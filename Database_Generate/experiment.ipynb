{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "from rdkit.Chem.rdmolfiles import MolFromSmiles\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit.Chem.AllChem import GetMorganGenerator, AdditionalOutput\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from modelTools import train_and_test_model, shap_frequency_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preapre the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predefine the dataset file name\n",
    "dataset_filename = {\n",
    "    \"RO\" : \"Data/P25_RO_ComVersion_OnlyPhotocat.xlsx\",\n",
    "    \"EtOH\" : \"Data/P25_ETOH_ComVersion_Comprehensive.xlsx\",\n",
    "    \"CHCl3\" : \"Data/P25_CHCl3_ComVersion_Comprehensive.xlsx\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"RO\" # dataset name only can be \"RO\", \"EtOH\", \"CHCl3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dataset_filename[dataset_name]\n",
    "current_dir = os.getcwd()\n",
    "raw_data_file = os.path.join(current_dir, filename)\n",
    "raw_data_excel = pd.read_excel(raw_data_file)\n",
    "\n",
    "raw_data_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns not exposed to models\n",
    "column_drop = [\"Catalyst\", \"Count\", \"n1\", \"n2\"]\n",
    "\n",
    "#Remove Reso data, removal % could not be accurately measured\n",
    "cleaned_dataset = raw_data_excel[raw_data_excel['Dye'] != \"Reso\"]\n",
    "\n",
    "#Remove Photolysis and Pre-Irradiation Time 0 measurements\n",
    "cleaned_dataset = cleaned_dataset[cleaned_dataset['Catalyst'] != 0]\n",
    "\n",
    "cleaned_dataset = cleaned_dataset.drop(columns=column_drop)\n",
    "\n",
    "cleaned_dataset_drop_T0 = cleaned_dataset[cleaned_dataset['Rxn Time (min)'] != 0]\n",
    "\n",
    "# If removal value is negative, set it to 0\n",
    "cleaned_dataset_drop_T0['Removal %'] = cleaned_dataset_drop_T0['Removal %'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "cleaned_dataset_drop_T0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a Helper function to generate morgan fingerprints from dye structures\n",
    "def get_morgan_fp(dye_smiles_dict: dict, radius: int = 2, n_bits: int = 1024):\n",
    "    \"\"\"\n",
    "    Get Morgan Fingerprints for the dyes with the given SMILES strings, radius, n_bits, use_chirality, use_features\n",
    "\n",
    "    Return the molecule fingerprint dict, molecule fingerprint list dict and bit dict\n",
    "    \"\"\"\n",
    "    # overall dict\n",
    "    dye_morgan_fp_dict = {}\n",
    "    dye_morgan_fp_bit_dict = {}\n",
    "    dye_morgan_fp_lst_dict = {}\n",
    "\n",
    "    fp_gen = GetMorganGenerator(radius=radius, fpSize=n_bits)\n",
    "    ao = AdditionalOutput()\n",
    "    ao.CollectBitInfoMap()\n",
    "\n",
    "    for dye, smiles in dye_smiles_dict.items():\n",
    "        mol = MolFromSmiles(smiles)\n",
    "        fp = fp_gen.GetFingerprint(mol, additionalOutput=ao)\n",
    "\n",
    "        dye_morgan_fp_dict[dye] = fp\n",
    "        dye_morgan_fp_lst_dict[dye] = np.array(fp)\n",
    "        dye_morgan_fp_bit_dict[dye] = ao.GetBitInfoMap()\n",
    "\n",
    "        print(f\"The Dye is: {str(dye)}, non-zero elements: {np.count_nonzero(np.array(fp))}\")    \n",
    "    \n",
    "    return dye_morgan_fp_dict, dye_morgan_fp_lst_dict, dye_morgan_fp_bit_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a dictionary to hold the dye strings; Dye Abbreviations are keys, value is dye's SMILE string\n",
    "dye_smiles_dict = {}\n",
    "for index, row in cleaned_dataset_drop_T0.iterrows():\n",
    "    dye_smiles_dict[row['Dye']] = row['SMILES']\n",
    "\n",
    "dye_smiles_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the list of possible Morgan fingerprint \n",
    "radius_lst = [2]\n",
    "n_bits_lst = [4096]\n",
    "\n",
    "assert len(radius_lst) == len(n_bits_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the morgan fingerprints for the dyes with different parameters and store them in the dict, \n",
    "# key is the parameter tuple, value is the morgan fingerprints dict:  molecule fingerprint dict, molecule fingerprint list dict and bit dict\n",
    "\n",
    "#Originally intedended to compare different values of radius and number of bits, only implemented for single radius and n_bits (2,4096)\n",
    "\n",
    "morgan_fp_dict = {}\n",
    "for i in range(len(radius_lst)):\n",
    "    morgan_fp_dict[(radius_lst[i], n_bits_lst[i])] = (get_morgan_fp(dye_smiles_dict, radius_lst[i], n_bits_lst[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store Morgan Fingerprints in dataframe for later use\n",
    "smile_morgan_fp = pd.DataFrame(morgan_fp_dict[(2, 4096)][1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add morgan fingerprint into raw dataset based on the dye name\n",
    "clean_feature_dropT0_dataset_full = cleaned_dataset_drop_T0.join(smile_morgan_fp, on='Dye')\n",
    "\n",
    "# set name to string for later training purpose\n",
    "clean_feature_dropT0_dataset_full.columns = clean_feature_dropT0_dataset_full.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/Train Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For later purposes, copy dataset with dye column remaining at the beginning\n",
    "clean_feature_dropT0_dataset = clean_feature_dropT0_dataset_full.drop(columns=[\"SMILES\", \"Std Dev\"])\n",
    "target_name = \"Removal %\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_feature_dropT0_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For leave out sets, select which dye should be removed from training data, if all dyes are to be included, pass empty string -> \"\"\n",
    "remove_dye_name = \"Am\"\n",
    "\n",
    "removed_dye_dataset = clean_feature_dropT0_dataset[clean_feature_dropT0_dataset['Dye'] == remove_dye_name]\n",
    "clean_feature_dropT0_dataset = clean_feature_dropT0_dataset[clean_feature_dropT0_dataset['Dye'] != remove_dye_name]\n",
    "\n",
    "clean_feature_dropT0_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare datasets of the properties and targets\n",
    "properties_set = clean_feature_dropT0_dataset.drop(columns=target_name)\n",
    "properties_name = properties_set.columns.values\n",
    "target_set = clean_feature_dropT0_dataset[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For later analysis purposes, do not drop dye column before split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(properties_set, target_set, test_size=0.2, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If a dye was removed, re-add its data into the test dataset\n",
    "if remove_dye_name != \"\":\n",
    "    X_test = pd.concat([X_test, removed_dye_dataset.drop(columns=target_name)])\n",
    "    Y_test = pd.concat([Y_test, removed_dye_dataset[target_name]])\n",
    "    print(f\"Add removed dye {remove_dye_name} data into the test dataset\")\n",
    "else:\n",
    "    print(\"No dye is removed, no need to add removed dye data into the test dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the dye column for all and store the dye column for later check dye purpose\n",
    "X_train_dye = pd.DataFrame(X_train.pop(\"Dye\"), columns=[\"Dye\"])\n",
    "X_test_dye = pd.DataFrame(X_test.pop(\"Dye\"), columns=[\"Dye\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_use_LR = LinearRegression\n",
    "model_params_LR = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_use_RF = RandomForestRegressor\n",
    "model_params_RF = {\"max_depth\": 10, \"n_estimators\":500, \"oob_score\":True,  \"random_state\":17}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_use_NN = MLPRegressor\n",
    "model_params_NN = {'solver': 'lbfgs', \"max_iter\": 20000, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (20, 50), 'batch_size': 20, 'alpha': 0.01, 'activation': 'logistic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dict to store the model for later use; key is the model name, value is a tuple with model and model parameters\n",
    "model_dict = {\n",
    "    \"LR\" : (model_use_LR, model_params_LR),\n",
    "    \"RF\" : (model_use_RF, model_params_RF),\n",
    "    \"NN\" : (model_use_NN, model_params_NN)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define which model should be used for training\n",
    "model_use_name = \"LR\" # can only be \"LR\", \"RF\", \"NN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model that will be trained and tested\n",
    "model_use = model_dict[model_use_name][0]\n",
    "model_params = model_dict[model_use_name][1]    \n",
    "\n",
    "model_use_single = model_use(**model_params)\n",
    "\n",
    "model_use_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the model tools helper file to train and test the model, as well as perform cross validation\n",
    "model_use_single, msg = train_and_test_model(model_use_single, f\"{model_use_name} model\", X_train, Y_train, X_test, Y_test, cv=10)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model with the removed dye\n",
    "if remove_dye_name != \"\":\n",
    "    \n",
    "    removed_dye_properties = removed_dye_dataset.drop(columns=[target_name, \"Dye\"])\n",
    "    removed_dye_target = removed_dye_dataset[target_name]\n",
    "\n",
    "    removed_dye_predicted_values = model_use_single.predict(removed_dye_properties)\n",
    "\n",
    "    print(f\"The predicted values for the removed dye are {list(removed_dye_predicted_values)}\")\n",
    "    print(f\"The actual values for the removed dye are {list(removed_dye_target)}\")\n",
    "else:\n",
    "    print(\"No dye was removed, so no need to test the removed dye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convivient pause to check model performance\n",
    "raise RuntimeError(\"Stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Value Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP value for single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define helpers to explain the SHAP values of a trained model\n",
    "explainer = shap.Explainer(model_use_single.predict, X_train)\n",
    "shap_values = explainer(X_train, max_evals=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output top 20 most important SHAP values\n",
    "shap.plots.beeswarm(shap_values, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values.abs.max(0), max_display=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP value for multiple tests (Raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-run models with different random seeds to variability of the model\n",
    "# set parameters\n",
    "random_seed = 16\n",
    "split_random_num = 5\n",
    "model_random_num = 10\n",
    "\n",
    "#Since linear regression is not random, so model_random_num is None and give model_random_list = [None] instead and change split_random_num to the multiple of split_random_num and model_random_num\n",
    "if model_use_name == \"LR\":\n",
    "    model_random_list = [None]\n",
    "    split_random_num = split_random_num * model_random_num\n",
    "    model_random_num = None\n",
    "else:\n",
    "    model_random_list = None\n",
    "\n",
    "# Use make/train test set \n",
    "properties_use = properties_set\n",
    "target_use = target_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe of SHAP values produced by models with varied random seeds\n",
    "shap_value_raw_df, msg = shap_frequency_raw(model_use, model_params, properties_use, target_use, data_split_random_num=split_random_num, model_random_num=model_random_num, model_random_list=model_random_list, random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns that all values in this column are 0 to reduce the size of the dataframe\n",
    "shap_value_raw_df = shap_value_raw_df.loc[:, (shap_value_raw_df != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "shap_value_raw_df.to_csv(f\"shap_value_raw_all_drop_{model_use_name}_{dataset_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError(\"Stop here\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
